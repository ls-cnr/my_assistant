# Diario di Sviluppo: Assistente Personale con Avatar 3D - Parte II

## Implementazione del Componente ElevenLabs TTS

Dopo aver definito l'architettura generale e pianificato i test, ho iniziato l'implementazione concreta del sistema partendo dal componente di sintesi vocale ElevenLabs. Ho scelto di iniziare da questo componente perché ero molto curioso di testare la KEY che ci è stata messa a disposizione dall'azienda.

NOTA: ricordiamoci di dare credito al ElevenLabs quando il progetto sarà rilasciato come public.

### Analisi della Documentazione di ElevenLabs

La prima fase è stata un'attenta analisi della documentazione ufficiale di ElevenLabs. Ho studiato:
- L'API di Text-to-Speech
- I diversi endpoint disponibili
- I parametri configurabili
- I formati di output supportati

La documentazione ha rivelato che ElevenLabs offre diverse modalità di generazione vocale, tra cui:
- Conversione semplice di testo in audio
- Streaming di audio in tempo reale
- Generazione con dati di timing per la sincronizzazione

Ho notato che l'API `/v1/text-to-speech/:voice_id/stream-with-timing` avrebbe potuto fornire informazioni di timing precise a livello di carattere, potenzialmente utili per la sincronizzazione labiale. Tuttavia, ho deciso di esplorare dapprima l'approccio con Rhubarb Lip Sync, utilizzando l'endpoint base di ElevenLabs `/v1/text-to-speech/:voice_id`.

### Sviluppo della Classe ElevenLabsTTS

Ho creato una classe Python `ElevenLabsTTS` che incapsula la logica per interagire con l'API di ElevenLabs. Questa classe è responsabile di:
- Gestire l'autenticazione tramite API key
- Fornire metodi per elencare le voci disponibili
- Convertire testo in audio con varie impostazioni
- Salvare l'audio generato in file locali

La classe include configurazioni specifiche per ottimizzare l'output in italiano, come impostazioni di stabilità e similarity_boost adeguate.

Per il momento la classe si trova nella cartella dei test, ma se funziona correttamente potrebbe essere spostata nella cartella backend.

### Esplorazione delle Voci Disponibili

Un passaggio fondamentale è stato l'esplorazione delle voci disponibili su ElevenLabs, per trovare quelle più adatte all'italiano. Ho notato che l'endpoint per ottenere l'elenco delle voci è cambiato a `/v2/voices`, quindi ho dovuto aggiornare di conseguenza il codice.

Durante questa fase, ho creato uno script separato `voice_list.py` per ottenere informazioni dettagliate su tutte le voci disponibili. Ho implementato una visualizzazione in formato tabellare che riporta:
- ID della voce
- Nome
- Categoria
- Accento
- Età
- Genere
- Caso d'uso
- Descrizione

Questa visualizzazione ha facilitato la selezione della voce più adatta per il mio assistente. Ho scoperto che nessuna delle vocie supporta nativamente l'italiano: sono tutte multilingua e possono essere utilizzate con vari livelli di naturalezza.

### Selezione della Voce e Test Iniziali

Dopo l'analisi delle voci disponibili, ho selezionato "Matilda" come voce per il mio assistente, basandomi sulla sua qualità e naturalezza con l'italiano. L'ID della voce "XrExE9yKIg1WjnnlVkGX" è stato utilizzato per i test successivi.

Ho sviluppato uno script di test `test_eleven_labs.py` per verificare la sintesi vocale con diversi input:
- Frasi semplici in italiano
- Frasi più complesse con punteggiatura varia

I test hanno rivelato una buona qualità della sintesi vocale, con tempi di risposta accettabili (1.38 secondi per una frase breve e 2.46 secondi per una frase più lunga).

### Valutazione dei Risultati

I file audio generati sono stati analizzati per valutare:
- La naturalezza della pronuncia italiana
- La gestione dell'intonazione e della prosodia
- La qualità complessiva dell'audio

I risultati sono stati molto soddisfacenti, confermando che ElevenLabs è una scelta valida per la sintesi vocale in italiano. Ho deciso di procedere con questa soluzione per il mio assistente personale.

### Considerazioni sulla Sicurezza

Durante l'implementazione, ho notato che lo script di test conteneva l'API key direttamente nel codice. Questo rappresenta un rischio per la sicurezza per quando il repository verrà rilasciato. Ricordiamoci di migliorare questo aspetto utilizzando:
- Variabili d'ambiente
- File di configurazione separati

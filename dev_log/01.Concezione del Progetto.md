# Diario di Sviluppo: Assistente Personale con Avatar 3D

## Concezione del Progetto

L'idea iniziale è di un assistente personale più coinvolgente di un semplice assistente vocale. Qualcosa che gli utenti possano "vedere" mentre interagiscono con l'assistente, aggiungendo una dimensione visiva all'esperienza.

La visione è di creare un avatar 3D che:
- Risponda alle domande dell'utente
- Sia animato con sincronizzazione labiale precisa
- Sembri naturale e coinvolgente

Le sfide principali identificate in questa fase:
1. L'elaborazione dell'audio in input
2. La generazione di risposte significative
3. La creazione di un avatar 3D realistico
4. La sincronizzazione labiale con l'audio

## Ricerca delle Tecnologie

Dopo una ricerca approfondita, ho identificato diverse tecnologie potenziali per ciascun componente del sistema:

**Per l'elaborazione dell'audio e generazione risposte**:
- OpenAI Whisper + ChatGPT/GPT-4
- Qwen-Audio di Alibaba

**Per la sintesi vocale**:
- ElevenLabs si cui abbiamo una licenza Educational

**Per la sincronizzazione labiale**:
- Rhubarb Lip Sync

**Per l'avatar 3D**:
- Ready Player Me
- Mixamo

## Valutazione delle Opzioni

Dopo aver analizzato i pro e i contro di ciascuna tecnologia, ho selezionato le seguenti soluzioni:

**Per l'elaborazione audio e risposta**:
Mi piace Qwen-Audio perché:
- È un modello all-in-one che gestisce sia il riconoscimento vocale che l'analisi del contenuto (incluso l'aspetto emnozionale)
- Supporta molteplici lingue
- Può elaborare non solo voce ma anche altri tipi di audio (come suoni naturali e musica)

**Per la sintesi vocale**:
Mi piace ElevenLabs perché:
- Offre voci estremamente naturali
- Fornisce API ben documentate
- Potrebbe fornire dati di timing precisi che possono aiutare nella sincronizzazione labiale

**Per la sincronizzazione labiale**:
Mi piace Rhubarb Lip Sync perché:
- È open source e ha un'ottima reputazione nella community
- È specificamente progettato per la sincronizzazione labiale
- Mi evita di dover sviluppare la complessa logica di mappatura tra suoni e forme della bocca

**Per l'avatar 3D**:
Mi piace Ready Player Me perché:
- Offre avatar personalizzabili di alta qualità
- Supporta nativamente il sistema Oculus LipSync

## Definizione dell'Architettura

Dopo aver selezionato le tecnologie, ho definito la pipeline complessiva del sistema:

```
Audio input → [Qwen-Audio] → Testo trascritto → [ElevenLabs] → Audio sintetizzato
                                    ↓
                        [Rhubarb Lip Sync] → Dati sincronizzazione labiale
                                    ↓
                        [Ready Player Me] → Avatar 3D animato con sincronizzazione labiale
```

1. L'audio dell'utente viene elaborato da Qwen-Audio che fornisce una risposta testuale
2. Il testo viene inviato a ElevenLabs per generare una voce sintetizzata
3. L'audio generato viene analizzato da Rhubarb Lip Sync per creare dati di sincronizzazione labiale
4. Questi dati vengono utilizzati per animare un avatar 3D di Ready Player Me

Nota: probabilmente tra Qwen-Audio e ElevenLabs servirà posizionare una LLM per elaborare la risposta all'utente.

## Ricerca sull'Integrazione Ready Player Me e Oculus LipSync

Un'importante scoperta è stata che gli avatar Ready Player Me supportano nativamente le blend shapes di Oculus LipSync. Questo ha richiesto un approfondimento sulla documentazione di Oculus LipSync.

Le informazioni chiave emerse:
- Oculus LipSync utilizza un sistema di 15 visemi (forme della bocca)
- I visemi corrispondono a specifici suoni del parlato
- Il sistema è progettato per animare avatar 3D in modo realistico

Poiché Rhubarb Lip Sync utilizza un sistema di 9 forme della bocca (A-F, G, H, X), mentre Oculus LipSync ne utilizza 15, è stato necessario sviluppare una tabella di mappatura tra i due sistemi:

| Rhubarb | Oculus LipSync | Descrizione |
|---------|---------------|-------------|
| A (Chiusa) | PP | Labbra chiuse per suoni "P", "B", "M" |
| B (Denti stretti) | SS | Bocca leggermente aperta con denti visibili |
| C (Aperta) | E | Bocca aperta per vocali come "E" |
| D (Molto aperta) | aa | Bocca completamente aperta |
| E (Arrotondata) | oh | Bocca leggermente arrotondata |
| F (Sporgente) | ou | Labbra sporgenti |
| G (Denti superiori su labbro inferiore) | FF | Per suoni "F" e "V" |
| H (Lingua visibile) | nn o RR | Per suoni "L" prolungati |
| X (Riposo) | sil | Posizione di riposo |

## Analisi delle Potenziali Problematiche

Durante la progettazione dell'architettura, ho identificato alcune potenziali problematiche:

1. **Latenza**:
   - Multiple chiamate API in sequenza potrebbero generare ritardi percepibili
   - L'elaborazione di Rhubarb potrebbe introdurre ulteriore latenza

2. **Sincronizzazione Audio-Video**:
   - Sfasamenti tra audio e movimento delle labbra potrebbero risultare innaturali

3. **Qualità dell'Animazione**:
   - La mappatura tra Rhubarb e Oculus LipSync potrebbe non essere ottimale per tutti i fonemi

4. **Compatibilità delle API**:
   - Cambiamenti nelle API potrebbero richiedere aggiornamenti del codice

5. **Prestazioni su Dispositivi Mobili**:
   - Il rendering 3D potrebbe essere pesante per dispositivi a bassa potenza

## Pianificazione dei Test

Per garantire che ogni componente funzioni correttamente, ho pianificato una serie di test specifici:

1. **Test di Qwen-Audio**:
   - Verificare l'accuratezza della trascrizione
   - Testare la qualità delle risposte generate
   - Misurare i tempi di elaborazione

2. **Test di ElevenLabs**:
   - Valutare la naturalezza delle voci
   - Testare la generazione di audio in diverse lingue
   - Verificare la precisione dei dati di timing forniti

3. **Test di Rhubarb Lip Sync**:
   - Analizzare la qualità dei dati di sincronizzazione generati
   - Confrontare i risultati dei diversi riconoscitori (phonetic vs. pocketSphinx)
   - Verificare la compatibilità con l'audio generato da ElevenLabs

4. **Test di Conversione da Rhubarb a Oculus LipSync**:
   - Verificare che la mappatura tra i due sistemi funzioni come previsto
   - Controllare che la temporizzazione sia mantenuta accuratamente

5. **Test dell'Animazione su Ready Player Me**:
   - Valutare la naturalezza dell'animazione labiale
   - Verificare la sincronizzazione tra audio e movimenti
   - Identificare eventuali artefatti o problemi visivi

6. **Test di Integrazione Completa**:
   - Verificare il funzionamento end-to-end del sistema
   - Misurare i tempi di risposta complessivi
   - Valutare l'esperienza utente generale

Questi test sono progettati per essere eseguiti in modo incrementale, testando ogni componente individualmente prima di procedere all'integrazione completa.
